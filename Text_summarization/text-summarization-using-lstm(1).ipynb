{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Adding requirement for attention layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attention in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from attention) (1.26.4)\n",
      "Requirement already satisfied: tensorflow>=2.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from attention) (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=2.1->attention) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kngvi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "# copyfile(src = \"../input/attention/attention.py\", dst = \"../working/attention.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***importing required libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "_Jpu8qLEFxcY",
    "outputId": "95968e01-faac-4911-c802-9c008a4e62cf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from keras.utils import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings\n",
    "# from attention import AttentionLayer\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Loading dataset to the notebook***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wnK5o4Z1Fxcj"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Dropping duplicate reviews and null values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Cjul88oOFxcr"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Information about datatypes and shape of the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "__fy-JxTFxc9",
    "outputId": "d42c6e36-bbc8-43c2-de0e-d3effe3e8c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 393560 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      393560 non-null  int64 \n",
      " 1   ProductId               393560 non-null  object\n",
      " 2   UserId                  393560 non-null  object\n",
      " 3   ProfileName             393560 non-null  object\n",
      " 4   HelpfulnessNumerator    393560 non-null  int64 \n",
      " 5   HelpfulnessDenominator  393560 non-null  int64 \n",
      " 6   Score                   393560 non-null  int64 \n",
      " 7   Time                    393560 non-null  int64 \n",
      " 8   Summary                 393560 non-null  object\n",
      " 9   Text                    393560 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 33.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Dictionary for expanding the contractions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0s6IY-x2FxdL"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***For removing stopwords***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XZr-u3OEFxdT"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Function for cleaning reviews and summaries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***cleaning reviews and displaying***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A2QAeCHWFxdY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))\n",
    "cleaned_text[:5]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***cleaning summaries and displaying***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GsRXocxoFxd-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))\n",
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Adding columns into the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L1zLpnqsFxey"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Dropping empty rows***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sYK390unFxfA"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Visualization distribution of reviews and summaries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MdF76AHHFxgw",
    "outputId": "e3bbe165-4235-482f-bfd4-36a3f1d95290"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7JRjwdIOFxg3",
    "outputId": "f968be82-c539-471d-ce23-16f18b059ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980140281988159\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=10):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9130307623446116\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_text']:\n",
    "    if(len(i.split())<=80):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZKD5VOWqFxhC"
   },
   "outputs": [],
   "source": [
    "max_text_len=80\n",
    "max_summary_len=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***getting rid of outliers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yY0tEJP0FxhI"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Adding tokens at the beginning and the end of summary***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EwLUH78CFxhg"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "Summary: sostok good quality dog food eostok\n",
      "\n",
      "\n",
      "Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
      "Summary: sostok not as advertised eostok\n",
      "\n",
      "\n",
      "Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
      "Summary: sostok delight says it all eostok\n",
      "\n",
      "\n",
      "Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
      "Summary: sostok cough medicine eostok\n",
      "\n",
      "\n",
      "Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
      "Summary: sostok great taffy eostok\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Review:\",df['text'][i])\n",
    "    print(\"Summary:\",df['summary'][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***splitting traing and test set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RakakKHcFxhl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.05,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***prepare a tokenizer for reviews on training data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oRHTgX6hFxhq"
   },
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***calculating number of rare and common words in reviews***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "y8KronV2Fxhx",
    "outputId": "d2eb2f27-fbbc-4e61-9556-3c3ff5e4327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 67.99448802204792\n",
      "Total Coverage of rare words: 0.8633340536872359\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***defining tokenizer with most common words for reviews***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "J2giEsF3Fxh3"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DCbGMsm4FxiA",
    "outputId": "2d9165f0-e542-4114-91f3-e070d483fce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30195"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***prepare a tokenizer for summaries on training data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eRHqyBkBFxiJ"
   },
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***calculating number of rare and common words in summaries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yzE5OiRLFxiM",
    "outputId": "7f7a4f89-b088-4847-8172-09e5a2383d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 74.62345486652124\n",
      "Total Coverage of rare words: 1.869156915502513\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***defining tokenizer with most common words for summaries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-fswLvIgFxiR"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for summaries on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***checking word count of start token is equal to length of the training data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pR8IX9FRFxiY",
    "outputId": "b116cdbd-42c4-4ede-9f6d-46284115393e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335878, 335878)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***deleting the rows that contain only START and END tokens***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kZ-vW82sFxih"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cx5NISuMFxik"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Model building, defining LSTM layers, Encoder and Decoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_kg_hide-output": false,
    "id": "zXef38nBFxir",
    "outputId": "7ae99521-46f8-4c6f-9cba-4979deffeee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kngvi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " embedding            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,019,500</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">481,200</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                     \n",
       "\n",
       " input_layer_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span>  lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                     \n",
       "\n",
       " embedding_1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">733,000</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span>  lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                     \n",
       "\n",
       " lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">481,200</span>  embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
       "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
       "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                            \n",
       "\n",
       " attention_layer      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>  lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>)                                 lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " concat_layer         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " time_distributed     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,330</span>  concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">7330</span>)                                            \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " embedding            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m3,019,500\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lstm (\u001b[38;5;33mLSTM\u001b[0m)          [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m),     \u001b[38;5;34m481,200\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),                                     \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]                                     \n",
       "\n",
       " input_layer_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m),     \u001b[38;5;34m721,200\u001b[0m  lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),                                     \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]                                     \n",
       "\n",
       " embedding_1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m733,000\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m),     \u001b[38;5;34m721,200\u001b[0m  lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),                                     \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]                                     \n",
       "\n",
       " lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,         \u001b[38;5;34m481,200\u001b[0m  embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
       "                      \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
       "                      \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
       "                      \u001b[38;5;34m300\u001b[0m)]                                            \n",
       "\n",
       " attention_layer      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m)           \u001b[38;5;34m300\u001b[0m  lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       " (\u001b[38;5;33mAdditiveAttention\u001b[0m)                                 lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " concat_layer         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)           \u001b[38;5;34m0\u001b[0m  lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       attention_layer[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " time_distributed     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,        \u001b[38;5;34m4,405,330\u001b[0m  concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       " (\u001b[38;5;33mTimeDistributed\u001b[0m)    \u001b[38;5;34m7330\u001b[0m)                                            \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,562,930</span> (40.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,562,930\u001b[0m (40.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,562,930</span> (40.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,562,930\u001b[0m (40.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "attn_out = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " encoder_inputs       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " embedding            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span>  encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">481,200</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                     \n",
       "\n",
       " decoder_inputs       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span>  lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                     \n",
       "\n",
       " embedding_1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span>  decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span>  lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                     \n",
       "\n",
       " lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">481,200</span>  embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
       "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
       "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                                            \n",
       "\n",
       " attention_layer      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>  lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>)                                 lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       "\n",
       " concat_layer         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " time_distributed     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">6,010,000</span>  concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)                                           \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " encoder_inputs       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " embedding            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m1,000,000\u001b[0m  encoder_inputs[\u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lstm (\u001b[38;5;33mLSTM\u001b[0m)          [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m),     \u001b[38;5;34m481,200\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),                                     \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]                                     \n",
       "\n",
       " decoder_inputs       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m),     \u001b[38;5;34m721,200\u001b[0m  lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),                                     \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]                                     \n",
       "\n",
       " embedding_1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)   \u001b[38;5;34m1,000,000\u001b[0m  decoder_inputs[\u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m),     \u001b[38;5;34m721,200\u001b[0m  lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),                                     \n",
       "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]                                     \n",
       "\n",
       " lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,         \u001b[38;5;34m481,200\u001b[0m  embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
       "                      \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
       "                      \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
       "                      \u001b[38;5;34m300\u001b[0m)]                                            \n",
       "\n",
       " attention_layer      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         \u001b[38;5;34m300\u001b[0m  lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       " (\u001b[38;5;33mAdditiveAttention\u001b[0m)                                 lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       "\n",
       " concat_layer         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)           \u001b[38;5;34m0\u001b[0m  lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       attention_layer[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " time_distributed     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,        \u001b[38;5;34m6,010,000\u001b[0m  concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       " (\u001b[38;5;33mTimeDistributed\u001b[0m)    \u001b[38;5;34m10000\u001b[0m)                                           \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,415,100</span> (39.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,415,100\u001b[0m (39.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,415,100</span> (39.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,415,100\u001b[0m (39.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, AdditiveAttention, Concatenate, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Clear any previous sessions to avoid clutter from other models\n",
    "K.clear_session()\n",
    "\n",
    "# Model Parameters\n",
    "latent_dim = 300\n",
    "embedding_dim = 100\n",
    "x_voc = 10000  # Vocabulary size of the encoder (modify according to your data)\n",
    "y_voc = 10000  # Vocabulary size of the decoder (modify according to your data)\n",
    "max_text_len = 80  # Max length of input sequence\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,), name=\"encoder_inputs\")\n",
    "\n",
    "# Embedding layer for the encoder\n",
    "enc_emb = Embedding(input_dim=x_voc, output_dim=embedding_dim, trainable=True)(encoder_inputs)\n",
    "\n",
    "# Stacking 3 LSTM layers in the encoder\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\n",
    "\n",
    "# Embedding layer for the decoder\n",
    "dec_emb_layer = Embedding(input_dim=y_voc, output_dim=embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# LSTM for the decoder, using the encoder's final states as initial states\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer to align the encoder and decoder outputs\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Concatenate attention output with the decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# Dense layer to predict the next word in the sequence\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Model definition\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Define callbacks (optional)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "# # Pad your sequences to ensure they have the same length (input)\n",
    "# x_tr = pad_sequences(x_tr, maxlen=max_text_len, padding='post')\n",
    "# y_tr = pad_sequences(y_tr, maxlen=max_text_len, padding='post')\n",
    "# x_val = pad_sequences(x_val, maxlen=max_text_len, padding='post')\n",
    "# y_val = pad_sequences(y_val, maxlen=max_text_len, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index in x_tr: 9999, Expected max: 9999\n",
      "Max index in y_tr: 7328, Expected max: 9999\n"
     ]
    }
   ],
   "source": [
    "# After padding your sequences\n",
    "x_tr = pad_sequences(x_tr, maxlen=max_text_len, padding='post')\n",
    "y_tr = pad_sequences(y_tr, maxlen=max_text_len, padding='post')\n",
    "\n",
    "# Check and adjust indices\n",
    "x_tr[x_tr >= x_voc] = 0  # Replace out-of-vocab indices with 0\n",
    "y_tr[y_tr >= y_voc] = 0  # Replace out-of-vocab indices with 0\n",
    "\n",
    "# Check max indices again\n",
    "max_x_index = np.max(x_tr)\n",
    "max_y_index = np.max(y_tr)\n",
    "\n",
    "print(f\"Max index in x_tr: {max_x_index}, Expected max: {x_voc - 1}\")\n",
    "print(f\"Max index in y_tr: {max_y_index}, Expected max: {y_voc - 1}\")\n",
    "\n",
    "# Proceed to fit the model if indices are valid\n",
    "if max_x_index < x_voc and max_y_index < y_voc:\n",
    "    history = model.fit(\n",
    "        [x_tr, y_tr[:, :-1]], \n",
    "        y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:], \n",
    "        epochs=1, \n",
    "        batch_size=512, \n",
    "        validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]), \n",
    "        callbacks=[es, mc]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Indices in input data exceed vocabulary size after adjustments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwfi1Fm8Fxiz"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***monitoring the validation loss***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-A3J92MUljB"
   },
   "outputs": [],
   "source": [
    "# es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2), \n",
    "#       ModelCheckpoint('./MyModel_tf.keras',monitor='val_loss', verbose=1,\n",
    "#                       save_best_only=True, mode='min', save_weights_only = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***train the model on a batch size of 512 and validate it on the 10% of dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "id": "ETnPzA4OFxi3",
    "outputId": "477e374f-7cf2-4d60-f86e-2c49c9cebedb"
   },
   "outputs": [],
   "source": [
    "# history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"summary.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"summary.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***understanding the behavior of model over time***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDTNLAURFxjE",
    "outputId": "e2ea6e44-3931-4014-97a1-03fa2a441228"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***convert the index to word for summaries and reviews vocabulary***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBX0zZnOFxjW"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Setting up the inference for the encoder and decoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QkrNV-4Fxjt"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Defining a functio for implementation of the inference process***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f6TTFnBFxj6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***converting an integer sequence to a word sequence for summaries and reviews***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAUntznIFxj9"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***displaying some summaries generated by the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUtQmQTmFxkI",
    "outputId": "f407d9fc-e0cd-4082-98f5-bd1f562dc26f"
   },
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 18,
     "sourceId": 2157,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 717875,
     "sourceId": 1249711,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29955,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
